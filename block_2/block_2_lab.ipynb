{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# 1. Packages and Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# tf.enable_eager_execution() # Allows us to not need to initalize variables (more below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Graphing\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will be introduced as needed below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# 2. Tensorflow basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source:\n",
    "\n",
    "* https://tf.wiki/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## 2.1 Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are different versions of tensorflow, one that is for CPU execution and one for GPU usage. More details are provided in the wiki above, for simplicity we will just use the 'vanialla' cpu option to avoid difficulties with installation. \n",
    "\n",
    "The GPU options is definitely worth looking into if you have the local hardware and expect to do some heavy deep learning work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " `pip install tensorflow` will do the cpu version\n",
    " \n",
    "`pip install tensorflow-gpu` will do the gpu version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## 2.2 Set up variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is advisable to work through the tensorflow documentation on variables. A brief summary and some code is below.\n",
    "\n",
    "* https://www.tensorflow.org/guide/variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some important commands to get to know:\n",
    "\n",
    "`tf.get_variable()` a useful function for creating variables. You can give it an initialiser and other commands. (https://www.tensorflow.org/api_docs/python/tf/get_variable)\n",
    "\n",
    "`tf.constant` creates a tensorflow tensor. (https://www.tensorflow.org/api_docs/python/tf/constant)\n",
    "\n",
    "`tf.Variable` is a constructor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also generate data\n",
    "one_eg = tf.ones(shape=(3,3))\n",
    "random_eg = tf.random_uniform([3,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look\n",
    "one_eg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look\n",
    "random_eg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a variety of functions to utilise your variables. A popular need being matrix multiplication:\n",
    "\n",
    "`tf.matmul` for matrix multiplication. This takes in two arguments and performs the multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = tf.constant([[1, 2], [3, 4]])\n",
    "B = tf.constant([[5, 6], [7, 8]])\n",
    "C = tf.matmul(A, B)\n",
    "\n",
    "print(C)\n",
    "\n",
    "# Can confirm on https://matrix.reshish.com/multCalculation.php"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## 2.2 Create a computation graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could therefore set up the computation graph from our lecture notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://s3-ap-southeast-2.amazonaws.com/mdsi-deep-learn-aut-19/comp_graph.png\" width=\"250\" height=\"250\"/>\n",
    "<style>\n",
    " img {\n",
    "    vertical-align: middle;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the tensorflow GradientTape API to assist our small computation graph example. From the documentation:\n",
    "\n",
    "_TensorFlow provides the tf.GradientTape API for automatic differentiation - computing the gradient of a computation with respect to its input variables. Tensorflow \"records\" all operations executed inside the context of a tf.GradientTape onto a \"tape\". Tensorflow then uses that tape and the gradients associated with each recorded operation to compute the gradients of a \"recorded\" computation using reverse mode differentiation._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemError",
     "evalue": "<built-in function TFE_Py_TapeWatch> returned a result with an error set",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'RefVariable' object has no attribute '_id'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-b1157748147b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Our next layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/Dev/py-vms/ml-env/lib/python3.6/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mwatch\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    778\u001b[0m         \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwatch_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mtf_contextlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontextmanager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/Dev/py-vms/ml-env/lib/python3.6/site-packages/tensorflow/python/eager/tape.py\u001b[0m in \u001b[0;36mwatch\u001b[0;34m(tape, tensor)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mwatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m   \u001b[0;34m\"\"\"Marks this tensor to be watched by the given tape.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m   \u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFE_Py_TapeWatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSystemError\u001b[0m: <built-in function TFE_Py_TapeWatch> returned a result with an error set"
     ]
    }
   ],
   "source": [
    "x = tf.Variable(3.0, name=\"x\")\n",
    "y = tf.Variable(2.0, name=\"y\")\n",
    "z = tf.Variable(4.0, name=\"z\")\n",
    "\n",
    "with tf.GradientTape() as t:\n",
    "    t.watch(x)\n",
    "    \n",
    "    # Our next layer\n",
    "    a = tf.add(x,y, name=\"a\")\n",
    "    b = tf.multiply(a, z, name=\"b\")\n",
    "    f = tf.square(b, name=\"f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://s3-ap-southeast-2.amazonaws.com/mdsi-deep-learn-aut-19/com_graph_diff.png\" width=\"450\" height=\"450\"/>\n",
    "<style>\n",
    " img {\n",
    "    vertical-align: middle;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From our slide above, if we set the values of x=3, y=2, z=4 we expect F to be ((3+2)x4)^2. See our differentiation step if we wanted to differentiate this computation graph with respect to A.\n",
    "\n",
    "We expect the value to be 2BZ which is 2((3+2)x4)x4 = 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'b' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-8ecb6b97b41f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# We could also just ask for b back to simplify the above:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'b' is not defined"
     ]
    }
   ],
   "source": [
    "# We could also just ask for b back to simplify the above:\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can differentiate \n",
    "# See more here https://www.tensorflow.org/tutorials/eager/automatic_differentiation\n",
    "df_da = t.gradient(f, a)\n",
    "df_da"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## 2.3 Initialise variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we dive in, a note on 'Ops':\n",
    "\n",
    "* https://stackoverflow.com/questions/43290373/what-is-tensorflow-op-does\n",
    "\n",
    "_TensorFlow is a programming system in which you represent computations as graphs. Nodes in the graph are called ops (short for operations). An op takes zero or more Tensors, performs some computation, and produces zero or more Tensors._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the tensorflow documentation:\n",
    "\n",
    "_Before you can use a variable, it must be initialized. If you are programming in the low-level TensorFlow API (that is, you are explicitly creating your own graphs and sessions), you must explicitly initialize the variables. Most high-level frameworks such as `tf.contrib.slim`, `tf.estimator.Estimator` and `Keras` automatically initialize variables for you before training a model_\n",
    "\n",
    "The convenience function `tf.global_variables_initializer()` is a handy way to ad an Op that will initialise your global variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `Session` object is an encapsulation of the environment where the `Ops` can take place using the `Tensor` objects. We need sessions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage, restart the kernel and don't have `enable_eager_execution`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'b:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.Variable(3.0, name=\"x\")\n",
    "y = tf.Variable(2.0, name=\"y\")\n",
    "z = tf.Variable(4.0, name=\"z\")\n",
    "\n",
    "# Our next layer\n",
    "a = tf.add(x,y, name=\"a\")\n",
    "b = tf.multiply(a, z, name=\"b\")\n",
    "f = tf.square(b, name=\"f\")\n",
    "\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of the equation is : 400.0\n"
     ]
    }
   ],
   "source": [
    "# Add an Op to initialize global variables.\n",
    "\n",
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "# Now we create a session\n",
    "with tf.Session() as sess:\n",
    "     \n",
    "    # initialize the variables\n",
    "    sess.run(init_op)\n",
    "     \n",
    "    # run the operation\n",
    "    output = sess.run(f)\n",
    "  \n",
    "    print(\"Value of the equation is : {}\".format(output))\n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# 3. A practical example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adapted from:\n",
    "* https://appliedmachinelearning.blog/2018/12/26/tensorflow-tutorial-from-scratch-building-a-deep-learning-model-on-fashion-mnist-dataset-part-1/    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "data_dir = os.getcwd() + \"/new_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    with open(filename, 'rb') as file_in:\n",
    "        dataset = pickle.load(file_in)\n",
    "        file_in.close()\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files():\n",
    "    global X_train, X_test, X_val, y_train, y_test, y_val\n",
    "    file_list = [\"X_train.pkl\", \"X_test.pkl\", \n",
    "                 \"y_train.pkl\", \"y_test.pkl\",\n",
    "                \"X_val.pkl\", \"y_val.pkl\"]\n",
    "    file_list = [data_dir + \"/\" + x for x in file_list]\n",
    "\n",
    "    X_train = read_file(file_list[0])\n",
    "    X_test = read_file(file_list[1])\n",
    "    y_train = read_file(file_list[2])\n",
    "    y_test = read_file(file_list[3])\n",
    "    \n",
    "    X_val = read_file(file_list[4])\n",
    "    y_val = read_file(file_list[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54000, 784) (10000, 784) (6000, 784) (54000,) (10000,) (6000,)\n"
     ]
    }
   ],
   "source": [
    "#Confirm it worked\n",
    "print(X_train.shape,X_test.shape, X_val.shape, y_train.shape, y_test.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## 3.1 Some setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input = 784\n",
    "n_hidden1 = 128\n",
    "n_hidden2 = 128\n",
    "n_class = 10\n",
    "n_epoch = 20\n",
    "learning_rate = 0.001\n",
    "batch_size = 128\n",
    "dropout = 0.20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## 3.2 Forward Prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our forward layer\n",
    "\n",
    "def model(batch_x):\n",
    " \n",
    "    \"\"\"\n",
    "    We will define the learned variables, the weights and biases,\n",
    "    within the method ``model()`` which also constructs the neural network.\n",
    "    The variables named ``hn``, where ``n`` is an integer, hold the learned weight variables. \n",
    "    The variables named ``bn``, where ``n`` is an integer, hold the learned bias variables.\n",
    "    \"\"\"\n",
    " \n",
    "    b1 = tf.get_variable(\"b1\", [n_hidden1], initializer = tf.zeros_initializer())\n",
    "    h1 = tf.get_variable(\"h1\", [n_input, n_hidden1], initializer = tf.contrib.layers.xavier_initializer())\n",
    "    layer1 = tf.nn.relu(tf.add(tf.matmul(batch_x,h1),b1))\n",
    " \n",
    "    b2 = tf.get_variable(\"b2\", [n_hidden2], initializer = tf.zeros_initializer())\n",
    "    h2 = tf.get_variable(\"h2\", [n_hidden1, n_hidden2], initializer = tf.contrib.layers.xavier_initializer())\n",
    "    layer2 = tf.nn.relu(tf.add(tf.matmul(layer1,h2),b2))\n",
    " \n",
    "    b3 = tf.get_variable(\"b3\", [n_class], initializer = tf.zeros_initializer())\n",
    "    h3 = tf.get_variable(\"h3\", [n_hidden2, n_class], initializer = tf.contrib.layers.xavier_initializer())\n",
    "    layer3 = tf.add(tf.matmul(layer2,h3),b3)\n",
    " \n",
    "    return layer3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encode the labels\n",
    "def one_hot(n_class, Y):\n",
    "    \"\"\"\n",
    "    return one hot encoded labels to train output layers of NN model\n",
    "    \"\"\"\n",
    "    return np.eye(n_class)[Y]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## 3.3  Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See here for the useful nn module https://www.tensorflow.org/api_docs/python/tf/nn\n",
    "\n",
    "def compute_loss(predicted, actual):\n",
    "    \"\"\"\n",
    "    This routine computes the cross entropy log loss for each of output node/classes.\n",
    "    returns mean loss is computed over n_class nodes.\n",
    "    \"\"\"\n",
    " \n",
    "    total_loss = tf.nn.softmax_cross_entropy_with_logits_v2(logits = predicted,labels = actual)\n",
    "    avg_loss = tf.reduce_mean(total_loss)\n",
    "    \n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## 3.4  Optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an optimiser\n",
    "\n",
    "def create_optimizer():\n",
    " \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(n_class, Y):\n",
    "    \"\"\"\n",
    "    returns one hot encoded labels to train output layers of NN model\n",
    "    \"\"\"\n",
    "    return np.eye(n_class)[Y]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## 3.5 Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X_train, X_val, X_test, y_train, y_val, y_test, verbose = False):\n",
    "    \"\"\"\n",
    "    Trains the network, also evaluates on test data finally.\n",
    "    \"\"\"\n",
    "    # Creating place holders for image data and its labels\n",
    "    X = tf.placeholder(tf.float32, [None, 784], name=\"X\")\n",
    "    Y = tf.placeholder(tf.float32, [None, 10], name=\"Y\")\n",
    " \n",
    "    # Forward pass on the model\n",
    "    logits = model(X)\n",
    " \n",
    "    # computing sofmax cross entropy loss with logits\n",
    "    avg_loss = compute_loss(logits, Y)\n",
    " \n",
    "    # create adams' optimizer, compute the gradients and apply gradients (minimize())\n",
    "    optimizer = create_optimizer().minimize(avg_loss)\n",
    " \n",
    "    # compute validation loss\n",
    "    validation_loss = compute_loss(logits, Y)\n",
    " \n",
    "    # evaluating accuracy on various data (train, val, test) set\n",
    "    correct_prediction = tf.equal(tf.argmax(logits,1), tf.argmax(Y,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    " \n",
    "    # initialize all the global variables\n",
    "    init = tf.global_variables_initializer()\n",
    " \n",
    "    # starting session to actually execute the computation graph\n",
    "    with tf.Session() as sess:\n",
    " \n",
    "        # all the global varibles holds actual values now\n",
    "        sess.run(init)\n",
    " \n",
    "        # looping over number of epochs\n",
    "        for epoch in range(n_epoch):\n",
    " \n",
    "            epoch_loss = 0.\n",
    " \n",
    "            # calculate number of batches in dataset\n",
    "            num_batches = np.round(X_train.shape[0]/batch_size).astype(int)\n",
    " \n",
    "            # looping over batches of dataset\n",
    "            for i in range(num_batches):\n",
    " \n",
    "                # selecting batch data\n",
    "                batch_X = X_train[(i*batch_size):((i+1)*batch_size),:]\n",
    "                batch_y = y_train[(i*batch_size):((i+1)*batch_size),:]\n",
    " \n",
    "                # execution of dataflow computational graph of nodes optimizer, avg_loss\n",
    "                _, batch_loss = sess.run([optimizer, avg_loss],\n",
    "                                                       feed_dict = {X: batch_X, Y:batch_y})\n",
    " \n",
    "                # summed up batch loss for whole epoch\n",
    "                epoch_loss += batch_loss\n",
    "            # average epoch loss\n",
    "            epoch_loss = epoch_loss/num_batches\n",
    " \n",
    "            # compute validation loss\n",
    "            val_loss = sess.run(validation_loss, feed_dict = {X: X_val ,Y: y_val})\n",
    " \n",
    "            # display within an epoch (train_loss, train_accuracy, valid_loss, valid accuracy)\n",
    "            if verbose:\n",
    "                print(\"epoch:{epoch_num}, train_loss: {train_loss}, train_accuracy: {train_acc}, val_loss: {valid_loss}, val_accuracy: {val_acc} \".format(\n",
    "                                                       epoch_num = epoch,\n",
    "                                                       train_loss = round(epoch_loss,3),\n",
    "                                                       train_acc = round(float(accuracy.eval({X: X_train, Y: y_train})),2),\n",
    "                                                       valid_loss = round(float(val_loss),3),\n",
    "                                                       val_acc = round(float(accuracy.eval({X: X_val, Y: y_val})),2)\n",
    "                                                      ))\n",
    " \n",
    "        # calculate final accuracy on never seen test data\n",
    "        print (\"Test Accuracy:\", accuracy.eval({X: X_test, Y: y_test}))\n",
    "        sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding of labels for output layer training\n",
    "y_train =  one_hot(n_class, y_train)\n",
    "y_val = one_hot(n_class, y_val)\n",
    "y_test = one_hot(n_class, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train_loss: 3.035, train_accuracy: 0.92, val_loss: 0.872, val_accuracy: 0.9 \n",
      "epoch:1, train_loss: 0.547, train_accuracy: 0.95, val_loss: 0.513, val_accuracy: 0.93 \n",
      "epoch:2, train_loss: 0.309, train_accuracy: 0.96, val_loss: 0.473, val_accuracy: 0.94 \n",
      "epoch:3, train_loss: 0.217, train_accuracy: 0.97, val_loss: 0.432, val_accuracy: 0.94 \n",
      "epoch:4, train_loss: 0.186, train_accuracy: 0.97, val_loss: 0.439, val_accuracy: 0.95 \n",
      "epoch:5, train_loss: 0.159, train_accuracy: 0.97, val_loss: 0.399, val_accuracy: 0.95 \n",
      "epoch:6, train_loss: 0.159, train_accuracy: 0.97, val_loss: 0.388, val_accuracy: 0.95 \n",
      "epoch:7, train_loss: 0.158, train_accuracy: 0.97, val_loss: 0.372, val_accuracy: 0.95 \n",
      "epoch:8, train_loss: 0.151, train_accuracy: 0.97, val_loss: 0.38, val_accuracy: 0.95 \n",
      "epoch:9, train_loss: 0.126, train_accuracy: 0.98, val_loss: 0.324, val_accuracy: 0.96 \n",
      "epoch:10, train_loss: 0.113, train_accuracy: 0.98, val_loss: 0.379, val_accuracy: 0.96 \n",
      "epoch:11, train_loss: 0.113, train_accuracy: 0.97, val_loss: 0.404, val_accuracy: 0.95 \n",
      "epoch:12, train_loss: 0.108, train_accuracy: 0.98, val_loss: 0.407, val_accuracy: 0.95 \n",
      "epoch:13, train_loss: 0.094, train_accuracy: 0.98, val_loss: 0.359, val_accuracy: 0.96 \n",
      "epoch:14, train_loss: 0.097, train_accuracy: 0.98, val_loss: 0.361, val_accuracy: 0.96 \n",
      "epoch:15, train_loss: 0.098, train_accuracy: 0.98, val_loss: 0.369, val_accuracy: 0.96 \n",
      "epoch:16, train_loss: 0.075, train_accuracy: 0.99, val_loss: 0.265, val_accuracy: 0.97 \n",
      "epoch:17, train_loss: 0.065, train_accuracy: 0.99, val_loss: 0.288, val_accuracy: 0.96 \n",
      "epoch:18, train_loss: 0.067, train_accuracy: 0.99, val_loss: 0.273, val_accuracy: 0.96 \n",
      "epoch:19, train_loss: 0.065, train_accuracy: 0.99, val_loss: 0.275, val_accuracy: 0.96 \n",
      "Test Accuracy: 0.9682\n"
     ]
    }
   ],
   "source": [
    "# Let's train and evaluate the fully connected NN model\n",
    "train(X_train, X_val, X_test, y_train, y_val, y_test, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# 4. An extended tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Work through this tutorial:\n",
    "\n",
    "* https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/#1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# 5. In Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source:\n",
    "\n",
    "* https://github.com/keras-team/keras/blob/master/examples/mnist_mlp.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 10\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n",
      "[5 0 4 1 9]\n",
      "(60000, 10)\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(y_train[0:5])\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_train[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build a simple model\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 0.2488 - acc: 0.9236 - val_loss: 0.1191 - val_acc: 0.9610\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 4s 74us/step - loss: 0.1036 - acc: 0.9687 - val_loss: 0.0815 - val_acc: 0.9747\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 4s 74us/step - loss: 0.0759 - acc: 0.9768 - val_loss: 0.0677 - val_acc: 0.9807\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 4s 74us/step - loss: 0.0607 - acc: 0.9818 - val_loss: 0.0716 - val_acc: 0.9807\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 5s 77us/step - loss: 0.0510 - acc: 0.9846 - val_loss: 0.0779 - val_acc: 0.9799\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 4s 74us/step - loss: 0.0442 - acc: 0.9872 - val_loss: 0.0686 - val_acc: 0.9825\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 0.0392 - acc: 0.9887 - val_loss: 0.0712 - val_acc: 0.9823\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 0.0366 - acc: 0.9893 - val_loss: 0.0699 - val_acc: 0.9846\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.0316 - acc: 0.9905 - val_loss: 0.0768 - val_acc: 0.9839\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.0301 - acc: 0.9916 - val_loss: 0.0729 - val_acc: 0.9841\n",
      "Test loss: 0.07285254494211403\n",
      "Test accuracy: 0.9841\n"
     ]
    }
   ],
   "source": [
    "# Run it\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
